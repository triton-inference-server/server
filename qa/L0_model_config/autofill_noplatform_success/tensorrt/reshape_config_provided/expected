name: "reshape_config_provided"
platform: "tensorrt_plan"
version_policy {
  latest {
    num_versions: 1
  }
}
max_batch_size: 8
input {
  name: "INPUT0"
  data_type: TYPE_FP32
  dims: 4
  dims: 4
  reshape {
    shape: 2
    shape: 2
    shape: 4
  }
}
input {
  name: "INPUT1"
  data_type: TYPE_FP32
  dims: 2
  reshape {
    shape: 1
    shape: 2
    shape: 1
  }
}
input {
  name: "INPUT2"
  data_type: TYPE_FP32
  dims: 2
  dims: 2
  dims: 3
  reshape {
    shape: 3
    shape: 2
    shape: 2
  }
}
input {
  name: "INPUT3"
  data_type: TYPE_FP32
  dims: 1
  reshape {
    shape: 1
    shape: 1
    shape: 1
  }
}
output {
  name: "OUTPUT0"
  data_type: TYPE_FP32
  dims: 2
  dims: 2
  dims: 4
}
output {
  name: "OUTPUT1"
  data_type: TYPE_FP32
  dims: 1
  dims: 2
  dims: 1
}
output {
  name: "OUTPUT2"
  data_type: TYPE_FP32
  dims: 3
  dims: 2
  dims: 2
}
output {
  name: "OUTPUT3"
  data_type: TYPE_FP32
  dims: 1
  dims: 1
  dims: 1
}
instance_group {
  name: "reshape_config_provided"
  count: 1
  gpus: 0
  kind: KIND_GPU
}
dynamic_batching {
  preferred_batch_size: 8
}
default_model_filename: "model.plan"
optimization {
  input_pinned_memory {
    enable: true
  }
  output_pinned_memory {
    enable: true
  }
}
backend: "tensorrt"
