# Copyright (c) 2018-2021, NVIDIA CORPORATION. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#
# Multistage build.
#

ARG BASE_IMAGE=tritonserver
ARG BUILD_IMAGE=tritonserver_build
ARG SDK_IMAGE=tritonserver_sdk
ARG TRITON_COMMON_REPO_TAG=main
ARG TRITON_CORE_REPO_TAG=main
ARG TRITON_THIRD_PARTY_REPO_TAG=main
ARG TRITON_BACKEND_REPO_TAG=main

############################################################################
## Build tests in the BUILD_IMAGE since it has already been configured
## correctly and has some existing build artifacts. Copy artifacts
## into QA area.
############################################################################
FROM ${BUILD_IMAGE} AS build

# Ensure apt-get won't prompt for selecting options
ENV DEBIAN_FRONTEND=noninteractive

WORKDIR /tmp/tritonbuild/tritonserver/build
ARG TRITON_COMMON_REPO_TAG
ARG TRITON_CORE_REPO_TAG
ARG TRITON_THIRD_PARTY_REPO_TAG
ARG TRITON_BACKEND_REPO_TAG
RUN cmake -DTRITON_ENABLE_GPU=ON \
          -DTRITON_COMMON_REPO_TAG:STRING=${TRITON_COMMON_REPO_TAG} \
          -DTRITON_CORE_REPO_TAG:STRING=${TRITON_CORE_REPO_TAG} \
          -DTRITON_THIRD_PARTY_REPO_TAG:STRING=${TRITON_THIRD_PARTY_REPO_TAG} \
          -DTRITON_BACKEND_REPO_TAG:STRING=${TRITON_BACKEND_REPO_TAG} /workspace/build && \
    make -j16 test-util

# Add inception_graphdef model to example repo
WORKDIR /workspace/docs/examples/model_repository
RUN mkdir -p inception_graphdef/1 && \
    wget -O /tmp/inception_v3_2016_08_28_frozen.pb.tar.gz \
        https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz && \
    (cd /tmp && tar xzf inception_v3_2016_08_28_frozen.pb.tar.gz) && \
    mv /tmp/inception_v3_2016_08_28_frozen.pb inception_graphdef/1/model.graphdef

# Update the qa/ directory with test executables, models, etc.
WORKDIR /workspace
RUN mkdir -p qa/common && \
    cp -r /workspace/src/backends/backend/examples/models/repeat_int32 qa/L0_decoupled/models/ && \
    cp -r /workspace/src/backends/backend/examples/models/square_int32 qa/L0_decoupled/models/ && \
    mkdir qa/L0_simple_example/models && \
    cp -r docs/examples/model_repository/simple qa/L0_simple_example/models/. && \
    mkdir qa/L0_simple_go_client/models && \
    cp -r docs/examples/model_repository/simple qa/L0_simple_go_client/models/. && \
    mkdir qa/L0_backend_release/simple_models && \
    cp -r docs/examples/model_repository/simple qa/L0_backend_release/simple_models/. && \
    mkdir qa/L0_backend_release/simple_seq_models && \
    cp -r /workspace/docs/examples/model_repository/simple_sequence qa/L0_backend_release/simple_seq_models/. && \
    mkdir qa/L0_shared_memory/models && \
    cp -r docs/examples/model_repository/simple qa/L0_shared_memory/models/. && \
    mkdir qa/L0_cuda_shared_memory/models && \
    cp -r docs/examples/model_repository/simple qa/L0_cuda_shared_memory/models/. && \
    mkdir qa/L0_client_java/models && \
    cp -r /workspace/docs/examples/model_repository/simple qa/L0_client_java/models && \
    mkdir qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/simple qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/simple_dyna_sequence qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/simple_int8 qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/simple_identity qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/simple_sequence qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/simple_string qa/L0_grpc/models && \
    cp -r /workspace/docs/examples/model_repository/inception_graphdef qa/L0_grpc/models && \
    mkdir qa/L0_http/models && \
    cp -r /workspace/docs/examples/model_repository/simple qa/L0_http/models && \
    cp -r /workspace/docs/examples/model_repository/simple_dyna_sequence qa/L0_http/models && \
    cp -r /workspace/docs/examples/model_repository/simple_identity qa/L0_http/models && \
    cp -r /workspace/docs/examples/model_repository/simple_sequence qa/L0_http/models && \
    cp -r /workspace/docs/examples/model_repository/simple_string qa/L0_http/models && \
    cp -r /workspace/docs/examples/model_repository/inception_graphdef qa/L0_http/models && \
    mkdir qa/L0_https/models && \
    cp -r docs/examples/model_repository/simple qa/L0_https/models/. && \
    mkdir qa/L0_secure_grpc/models && \
    cp -r docs/examples/model_repository/simple qa/L0_secure_grpc/models/. && \
    cp /tmp/tritonbuild/install/bin/simple qa/L0_simple_lib/. && \
    cp /tmp/tritonbuild/install/bin/memory_alloc qa/L0_io/. && \
    cp /tmp/tritonbuild/install/bin/multi_server qa/L0_multi_server/. && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/memory_test qa/L0_memory/. && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/pinned_memory_manager_test qa/L0_memory/. && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/triton_repo_agent_test qa/L0_triton_repo_agent/. && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/lib/libtritonrepoagent_relocation.so qa/L0_triton_repo_agent/. && \
#   FIXME: Uncomment after fixing the rate limiter unit tests to use the new TritonModel and
#   TritonModelInstance abstraction.
#   cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/rate_limiter_test qa/L0_rate_limiter/. && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/async_work_queue_test qa/L0_async_work_queue/. && \
    mkdir qa/L0_data_compression/models && \
    cp -r /workspace/docs/examples/model_repository/simple qa/L0_data_compression/models && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/data_compressor_test qa/L0_data_compression/.

# caffe2plan will not exist if the build was done without TensorRT enabled
RUN if [ -f /tmp/tritonbuild/tritonserver/build/test-util/install/bin/caffe2plan ]; then \
       cp /tmp/tritonbuild/tritonserver/build/test-util/install/bin/caffe2plan qa/common/.; \
    fi

RUN mkdir -p qa/L0_simple_ensemble/models/simple/1 && \
    cp /workspace/docs/examples/model_repository/simple/1/model.graphdef \
        qa/L0_simple_ensemble/models/simple/1/. && \
    mkdir -p qa/L0_simple_ensemble/models/simple/2 && \
    cp /workspace/docs/examples/model_repository/simple/1/model.graphdef \
        qa/L0_simple_ensemble/models/simple/2/. && \
    mkdir -p qa/L0_multiple_ports/models/simple/1 && \
    cp /workspace/docs/examples/model_repository/simple/1/model.graphdef \
        qa/L0_multiple_ports/models/simple/1/.

RUN mkdir -p qa/L0_backend_identity/models && \
    cp -r src/backends/backend/examples/models/identity_fp32 qa/L0_backend_identity/models/. && \
    mkdir -p qa/L0_backend_identity/models/identity_fp32/1

RUN mkdir -p qa/custom_models/custom_sequence_int32/1 && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/backends/sequence/libtriton_sequence.so \
        qa/custom_models/custom_sequence_int32/1/. && \
    mkdir -p qa/custom_models/custom_dyna_sequence_int32/1 && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/backends/dyna_sequence/libtriton_dyna_sequence.so \
        qa/custom_models/custom_dyna_sequence_int32/1/.

# L0_lifecycle needs No-GPU build of identity backend
RUN cd /tmp/tritonbuild/identity && \
    rm -rf install build && mkdir build && cd build && \
    cmake -DTRITON_ENABLE_GPU=OFF \
        -DCMAKE_INSTALL_PREFIX:PATH=/tmp/tritonbuild/identity/install \
        -DTRITON_COMMON_REPO_TAG:STRING=${TRITON_COMMON_REPO_TAG} \
        -DTRITON_CORE_REPO_TAG:STRING=${TRITON_CORE_REPO_TAG} \
        -DTRITON_THIRD_PARTY_REPO_TAG:STRING=${TRITON_THIRD_PARTY_REPO_TAG} \
        -DTRITON_BACKEND_REPO_TAG:STRING=${TRITON_BACKEND_REPO_TAG} .. && \
    make -j16 install

RUN cp /tmp/tritonbuild/identity/install/backends/identity/libtriton_identity.so \
        qa/L0_lifecycle/. && \
    mkdir -p qa/L0_perf_nomodel/custom_models/custom_zero_1_float32/1 && \
    mkdir -p qa/L0_perf_pyclients/custom_models/custom_zero_1_int32/1 && \
    mkdir -p qa/L0_infer_shm && \
    cp -r qa/L0_infer/. qa/L0_infer_shm && \
    mkdir -p qa/L0_infer_cudashm && \
    cp -r qa/L0_infer/. qa/L0_infer_cudashm && \
    mkdir -p qa/L0_infer_valgrind && \
    cp -r qa/L0_infer/. qa/L0_infer_valgrind && \
    mkdir -p qa/L0_infer_tf2 && \
    cp -r qa/L0_infer/. qa/L0_infer_tf2 && \
    mkdir -p qa/L0_trt_shape_tensors_shm && \
    cp -r qa/L0_trt_shape_tensors/. qa/L0_trt_shape_tensors_shm && \
    mkdir -p qa/L0_trt_shape_tensors_cudashm && \
    cp -r qa/L0_trt_shape_tensors/. qa/L0_trt_shape_tensors_cudashm && \
    mkdir -p qa/L0_batcher_shm && \
    cp -r qa/L0_batcher/. qa/L0_batcher_shm && \
    mkdir -p qa/L0_batcher_cudashm && \
    cp -r qa/L0_batcher/. qa/L0_batcher_cudashm && \
    mkdir -p qa/L0_batcher_valgrind && \
    cp -r qa/L0_batcher/. qa/L0_batcher_valgrind && \
    mkdir -p qa/L0_sequence_batcher_shm && \
    cp -r qa/L0_sequence_batcher/. qa/L0_sequence_batcher_shm && \
    mkdir -p qa/L0_sequence_batcher_cudashm && \
    cp -r qa/L0_sequence_batcher/. qa/L0_sequence_batcher_cudashm && \
    mkdir -p qa/L0_sequence_batcher_valgrind && \
    cp -r qa/L0_sequence_batcher/. qa/L0_sequence_batcher_valgrind && \
    mkdir -p qa/L0_perf_nomodel_shm && \
    cp -r qa/L0_perf_nomodel/. qa/L0_perf_nomodel_shm && \
    mkdir -p qa/L0_perf_nomodel_cudashm && \
    cp -r qa/L0_perf_nomodel/. qa/L0_perf_nomodel_cudashm

# L0_model_control_stress will not be present if gitlab tests are not available
RUN if [ -d qa/L0_model_control_stress ]; then \
        mkdir -p qa/L0_model_control_stress_valgrind && \
            cp -r qa/L0_model_control_stress/. qa/L0_model_control_stress_valgrind && \
            mkdir -p qa/L0_model_control_stress_valgrind_massif && \
            cp -r qa/L0_model_control_stress/. qa/L0_model_control_stress_valgrind_massif; \
    fi

RUN cp /tmp/tritonbuild/install/backends/repeat/libtriton_repeat.so \
        qa/L0_model_config/.

RUN mkdir -p qa/L0_decoupled/models/repeat_int32/1 && \
    cp /tmp/tritonbuild/install/backends/repeat/libtriton_repeat.so \
        qa/L0_decoupled/models/repeat_int32/1/.
RUN mkdir -p qa/L0_decoupled/models/square_int32/1 && \
    cp /tmp/tritonbuild/install/backends/square/libtriton_square.so \
        qa/L0_decoupled/models/square_int32/1/.
RUN mkdir -p qa/L0_decoupled/models/identity_int32/1
RUN mkdir -p qa/L0_decoupled/models/simple_repeat/1 && \
    mkdir -p qa/L0_decoupled/models/fan_repeat/1 && \
    mkdir -p qa/L0_decoupled/models/sequence_repeat/1 && \
    mkdir -p qa/L0_decoupled/models/repeat_square/1 && \
    mkdir -p qa/L0_decoupled/models/nested_square/1
RUN mkdir -p qa/L0_repoagent_checksum/models/identity_int32/1 && \
    cp /tmp/tritonbuild/install/backends/identity/libtriton_identity.so \
        qa/L0_repoagent_checksum/models/identity_int32/1/.
RUN mkdir -p qa/L0_passive_instance/models/distributed_int32_int32_int32/1 && \
    cp /tmp/tritonbuild/tritonserver/build/test-util/install/backends/distributed_addsub/libtriton_distributed_addsub.so \
        qa/L0_passive_instance/models/distributed_int32_int32_int32/1/.

############################################################################
## Copy artifacts from sdk container
############################################################################
FROM ${SDK_IMAGE} AS sdk

WORKDIR /workspace
COPY --from=build /workspace/qa/ qa/
RUN mkdir -p qa/clients && mkdir -p qa/pkgs && \
    cp -a install/bin/* qa/clients/. && \
    cp install/lib/libgrpcclient.so qa/clients/. && \
    cp install/lib/libhttpclient.so qa/clients/. && \
    cp install/python/*.py qa/clients/. && \
    cp install/python/triton*.whl qa/pkgs/.
RUN cp client/src/go/*.go qa/L0_simple_go_client/. && \
    cp -r client/src/java qa/L0_client_java/.

############################################################################
## Create CI enabled image
############################################################################
FROM $BASE_IMAGE

# Ensure apt-get won't prompt for selecting options
ENV DEBIAN_FRONTEND=noninteractive

# install platform specific packages
RUN if [ $(cat /etc/os-release | grep 'VERSION_ID="20.04"' | wc -l) -ne 0 ]; then \
        apt-get update && \
        apt-get install -y --no-install-recommends \
                libpng-dev; \
    elif [ $(cat /etc/os-release | grep 'VERSION_ID="18.04"' | wc -l) -ne 0 ]; then \
        apt-get update && \
        apt-get install -y --no-install-recommends \
                libpng-dev; \
    else \
        echo "Ubuntu version must be either 18.04 or 20.04" && \
        exit 1; \
    fi

# CI/QA for memcheck requires valgrind
# libarchive-dev is required by Python backend
RUN apt-get update && apt-get install -y --no-install-recommends \
                              curl \
                              libopencv-dev \
                              libarchive-dev \
                              libopencv-core-dev \
                              libzmq3-dev \
                              python3-dev \
                              python3-pip \
                              python3-protobuf \
                              python3-setuptools \
                              swig \
                              nginx \
                              protobuf-compiler \
                              maven \
                              valgrind && \
    rm -rf /var/lib/apt/lists/*

# CI/QA expects "python" executable (not python3).
RUN rm -f /usr/bin/python && \
    ln -s /usr/bin/python3 /usr/bin/python

RUN pip3 install --upgrade wheel setuptools && \
    pip3 install --upgrade numpy pillow attrdict future grpcio requests gsutil awscli six grpcio-channelz azure-cli

# L0_http_fuzz is hitting similar issue with boofuzz with latest version (0.4.0):
# https://github.com/jtpereyda/boofuzz/issues/529
# Hence, fixing the boofuzz version to 0.3.0
RUN pip3 install 'boofuzz==0.3.0'

# go needed to example go client test.
ADD https://golang.org/dl/go1.16.3.linux-amd64.tar.gz go1.16.3.linux-amd64.tar.gz
RUN rm -rf /usr/local/go && tar -C /usr/local -xzf go1.16.3.linux-amd64.tar.gz
ENV GOPATH /root/go
ENV PATH $PATH:/usr/local/go/bin:$GOPATH/bin
RUN GO111MODULE=off go get github.com/golang/protobuf/protoc-gen-go && \
    GO111MODULE=off go get google.golang.org/grpc

# CI expects tests in /opt/tritonserver/qa. The triton-server (1000)
# user should own all artifacts in case CI is run using triton-server
# user.
WORKDIR /opt/tritonserver
COPY --chown=1000:1000 --from=sdk /workspace/qa/ qa/

# Remove CI tests that are meant to run only on build image and
# install the tritonserver/triton python client APIs.
RUN rm -fr qa/L0_copyrights qa/L0_build_variants && \
    find qa/pkgs/ -maxdepth 1 -type f -name \
    "tritonclient-*-manylinux1_x86_64.whl" | xargs printf -- '%s[all]' | \
    xargs pip3 install --upgrade

ENV LD_LIBRARY_PATH /opt/tritonserver/qa/clients:${LD_LIBRARY_PATH}
