
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; NVIDIA Triton Inference Server</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="https://js.hcaptcha.com/1/api.js"></script>
    <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html" />
    <link rel="shortcut icon" href="_static/nvidia-logo-vert-rgb-blk-for-screen.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
      
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="#">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NVIDIA Triton Inference Server</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started/quickstart.html">
   Quickstart
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  User Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/performance_tuning.html">
   Deploying your trained model using Triton
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/architecture.html">
   Triton Architecture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/model_repository.html">
   Model Repository
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="customization_guide/repository_agents.html">
   Repository Agent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/model_configuration.html">
   Model Configuration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/optimization.html">
   Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/ragged_batching.html">
   Ragged Batching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/rate_limiter.html">
   Rate Limiter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/model_analyzer.html">
   Model Analyzer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/perf_analyzer.html">
   Performance Analyzer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/model_management.html">
   Model Management
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/custom_operations.html">
   Custom Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/decoupled_models.html">
   Decoupled Backends and Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/response_cache.html">
   Triton Response Cache
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/metrics.html">
   Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/trace.html">
   Triton Server Trace
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/jetson.html">
   Triton Inference Server Support for Jetson and JetPack
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/v1_to_v2.html">
   Version 1 to Version 2 Migration
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="user_guide/faq.html">
   FAQ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Protocol Guides
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="customization_guide/inference_protocols.html">
   Inference Protocols and APIs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_binary_data.html">
   Binary Tensor Data Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_classification.html">
   Classification Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_logging.html">
   Logging Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_model_configuration.html">
   Model Configuration Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_model_repository.html">
   Model Repository Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_schedule_policy.html">
   Schedule Policy Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_sequence.html">
   Sequence Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_shared_memory.html">
   Shared-Memory Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_statistics.html">
   Statistics Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="protocol/extension_trace.html">
   Trace Extension
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Customization Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="customization_guide/build.html">
   Building Triton
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="customization_guide/compose.html">
   Customize Triton Container
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="customization_guide/test.html">
   Testing Triton
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="examples/jetson/README.html">
   Using Triton Inference Server as a shared library for execution on Jetson
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="examples/jetson/concurrency_and_dynamic_batching/README.html">
   Concurrent inference and dynamic batching
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/triton-inference-server/server"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/triton-inference-server/server/issues/new?title=Issue%20on%20page%20%2Findex.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="simple visible nav section-nav flex-column">
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><no title></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="simple visible nav section-nav flex-column">
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <div class="sd-container-fluid sd-sphinx-override sd-mt-4 sd-mb-4 sd-ml-1 sd-mr-1 docutils">
<div class="sd-row sd-g-2 sd-g-xs-2 sd-g-sm-1 sd-g-md-1 sd-g-lg-1 sd-flex-row-reverse docutils">
<div class="sd-col sd-d-flex-column sd-col-4 sd-col-xs-4 sd-col-sm-4 sd-col-md-4 sd-col-lg-4 docutils">
<a class="reference internal image-reference" href="_images/nvidia-logo-vert-rgb-blk-for-screen.png"><img alt="_images/nvidia-logo-vert-rgb-blk-for-screen.png" src="_images/nvidia-logo-vert-rgb-blk-for-screen.png" style="width: 300px;" /></a>
</div>
<div class="sd-col sd-d-flex-column sd-col-8 sd-col-xs-8 sd-col-sm-8 sd-col-md-8 sd-col-lg-8 sd-fs-3 docutils">
<p>NVIDIA Triton Inference Server</p>
</div>
</div>
</div>
<p>Triton Inference Server is an open source inference serving software that streamlines AI inferencing.
Triton enables teams to deploy any AI model from multiple deep learning and machine learning frameworks, including TensorRT, TensorFlow, PyTorch, ONNX, OpenVINO, Python, RAPIDS FIL, and more. Triton supports inference across cloud, data center,edge and embedded devices on NVIDIA GPUs, x86 and ARM CPU, or AWS Inferentia. Triton delivers optimized performance for many query types, including real time, batched, ensembles and audio/video streaming.</p>
<p>Major features include:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/triton-inference-server/backend#where-can-i-find-all-the-backends-that-are-available-for-triton">Supports multiple deep learning
frameworks</a></p></li>
<li><p><a class="reference external" href="https://github.com/triton-inference-server/fil_backend">Supports multiple machine learning
frameworks</a></p></li>
<li><p><a class="reference internal" href="user_guide/architecture.html#concurrent-model-execution"><span class="std std-doc">Concurrent model
execution</span></a></p></li>
<li><p><a class="reference internal" href="user_guide/model_configuration.html#dynamic-batcher"><span class="std std-doc">Dynamic batching</span></a></p></li>
<li><p><a class="reference internal" href="user_guide/model_configuration.html#sequence-batcher"><span class="std std-doc">Sequence batching</span></a> and
<span class="xref myst">implicit state management</span>
for stateful models</p></li>
<li><p>Provides <a class="reference external" href="https://github.com/triton-inference-server/backend">Backend API</a> that
allows adding custom backends and pre/post processing operations</p></li>
<li><p>Model pipelines using
<a class="reference internal" href="user_guide/architecture.html#ensemble-models"><span class="std std-doc">Ensembling</span></a> or <a class="reference external" href="https://github.com/triton-inference-server/python_backend#business-logic-scripting">Business
Logic Scripting
(BLS)</a></p></li>
<li><p><a class="reference internal" href="customization_guide/inference_protocols.html"><span class="doc std std-doc">HTTP/REST and GRPC inference
protocols</span></a> based on the community
developed <a class="reference external" href="https://github.com/kserve/kserve/tree/master/docs/predict-api/v2">KServe
protocol</a></p></li>
<li><p>A <a class="reference internal" href="customization_guide/inference_protocols.html#in-process-triton-server-api"><span class="std std-doc">C API</span></a> and
<a class="reference internal" href="customization_guide/inference_protocols.html#java-bindings-for-in-process-triton-server-api"><span class="std std-doc">Java API</span></a>
allow Triton to link directly into your application for edge and other in-process use cases</p></li>
<li><p><a class="reference internal" href="user_guide/metrics.html"><span class="doc std std-doc">Metrics</span></a> indicating GPU utilization, server
throughput, server latency, and more</p></li>
</ul>
<p>Join the Triton and TensorRT community and stay current on the latest product updates, bug fixes, content, best practices, and more. Need enterprise support? NVIDIA global support is available for Triton Inference Server with the NVIDIA AI Enterprise software suite.</p>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By NVIDIA<br/>
  
      &copy; Copyright 2022 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.<br/>
    Last updated on Oct 05, 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


<script type="text/javascript">_satellite.pageBottom();</script>
  </body>
</html>