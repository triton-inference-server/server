
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Quickstart &#8212; NVIDIA Triton Inference Server</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://js.hcaptcha.com/1/api.js"></script>
    <script src="//assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../_static/design-tabs.js"></script>
    <link rel="canonical" href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/getting_started/quickstart.html" />
    <link rel="shortcut icon" href="../_static/nvidia-logo-vert-rgb-blk-for-screen.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Deploying your trained model using Triton" href="../user_guide/performance_tuning.html" />
    <link rel="prev" title="&lt;no title&gt;" href="../contents.html" /> 
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
      
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nvidia-logo-horiz-rgb-blk-for-screen.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NVIDIA Triton Inference Server</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting Started
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Quickstart
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  User Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/performance_tuning.html">
   Deploying your trained model using Triton
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/architecture.html">
   Triton Architecture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/model_repository.html">
   Model Repository
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../customization_guide/repository_agents.html">
   Repository Agent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/model_configuration.html">
   Model Configuration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/optimization.html">
   Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/ragged_batching.html">
   Ragged Batching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/rate_limiter.html">
   Rate Limiter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/model_analyzer.html">
   Model Analyzer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/perf_analyzer.html">
   Performance Analyzer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/model_management.html">
   Model Management
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/custom_operations.html">
   Custom Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/decoupled_models.html">
   Decoupled Backends and Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/response_cache.html">
   Triton Response Cache
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/metrics.html">
   Metrics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/trace.html">
   Triton Server Trace
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/jetson.html">
   Triton Inference Server Support for Jetson and JetPack
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/v1_to_v2.html">
   Version 1 to Version 2 Migration
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../user_guide/faq.html">
   FAQ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Protocol Guides
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../customization_guide/inference_protocols.html">
   Inference Protocols and APIs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_binary_data.html">
   Binary Tensor Data Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_classification.html">
   Classification Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_logging.html">
   Logging Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_model_configuration.html">
   Model Configuration Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_model_repository.html">
   Model Repository Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_schedule_policy.html">
   Schedule Policy Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_sequence.html">
   Sequence Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_shared_memory.html">
   Shared-Memory Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_statistics.html">
   Statistics Extension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../protocol/extension_trace.html">
   Trace Extension
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Customization Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../customization_guide/build.html">
   Building Triton
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../customization_guide/compose.html">
   Customize Triton Container
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../customization_guide/test.html">
   Testing Triton
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../examples/jetson/README.html">
   Using Triton Inference Server as a shared library for execution on Jetson
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../examples/jetson/concurrency_and_dynamic_batching/README.html">
   Concurrent inference and dynamic batching
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/triton-inference-server/server"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/triton-inference-server/server/issues/new?title=Issue%20on%20page%20%2Fgetting_started/quickstart.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-model-repository">
   Create A Model Repository
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#launch-triton">
   Launch Triton
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-on-system-with-gpus">
     Run on System with GPUs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-on-cpu-only-system">
     Run on CPU-Only System
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#verify-triton-is-running-correctly">
     Verify Triton Is Running Correctly
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#send-an-infernce-request">
   Send an Infernce Request
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Quickstart</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-model-repository">
   Create A Model Repository
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#launch-triton">
   Launch Triton
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-on-system-with-gpus">
     Run on System with GPUs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#run-on-cpu-only-system">
     Run on CPU-Only System
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#verify-triton-is-running-correctly">
     Verify Triton Is Running Correctly
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#send-an-infernce-request">
   Send an Infernce Request
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                 <!--
# Copyright (c) 2018-2020, NVIDIA CORPORATION. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-->
<div class="tex2jax_ignore mathjax_ignore section" id="quickstart">
<h1>Quickstart<a class="headerlink" href="#quickstart" title="Permalink to this headline">#</a></h1>
<p>The Triton Inference Server is available as <a class="reference internal" href="../customization_guide/build.html"><span class="doc std std-doc">buildable source
code</span></a>, but the easiest way to install and run Triton is to
use the pre-built Docker image available from the <a class="reference external" href="https://ngc.nvidia.com">NVIDIA GPU
Cloud (NGC)</a>.</p>
<p>Launching and maintaining Triton Inference Server revolves around the use of building model repositories. This tutorial will cover:</p>
<ul class="simple">
<li><p>Creating a Model Repository</p></li>
<li><p>Launching Triton</p></li>
<li><p>Send an Inference Request</p></li>
</ul>
<div class="section" id="create-a-model-repository">
<h2>Create A Model Repository<a class="headerlink" href="#create-a-model-repository" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference internal" href="../user_guide/model_repository.html"><span class="doc std std-doc">model repository</span></a> is the directory where you
place the models that you want Triton to serve. An example model
repository is included in the
<span class="xref myst">docs/examples/model_repository</span>. Before
using the repository, you must fetch any missing model definition
files from their public model zoos via the provided script.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cd docs/examples
$ ./fetch_models.sh
</pre></div>
</div>
</div>
<div class="section" id="launch-triton">
<h2>Launch Triton<a class="headerlink" href="#launch-triton" title="Permalink to this headline">#</a></h2>
<p>Triton is optimized to provide the best inferencing performance by
using GPUs, but it can also work on CPU-only systems. In both cases
you can use the same Triton Docker image.</p>
<div class="section" id="run-on-system-with-gpus">
<h3>Run on System with GPUs<a class="headerlink" href="#run-on-system-with-gpus" title="Permalink to this headline">#</a></h3>
<p>Use the following command to run Triton with the example model
repository you just created. The <a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">NVIDIA Container
Toolkit</a> must be installed
for Docker to recognize the GPU(s). The –gpus=1 flag indicates that 1
system GPU should be made available to Triton for inferencing.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver --model-repository=/models
</pre></div>
</div>
<p>Where &lt;xx.yy&gt; is the version of Triton that you want to use (and
pulled above). After you start Triton you will see output on the
console showing the server starting up and loading the model. When you
see output like the following, Triton is ready to accept inference
requests.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">+----------------------+---------+--------+</span>
<span class="o">|</span> <span class="n">Model</span>                <span class="o">|</span> <span class="n">Version</span> <span class="o">|</span> <span class="n">Status</span> <span class="o">|</span>
<span class="o">+----------------------+---------+--------+</span>
<span class="o">|</span> <span class="o">&lt;</span><span class="n">model_name</span><span class="o">&gt;</span>         <span class="o">|</span> <span class="o">&lt;</span><span class="n">v</span><span class="o">&gt;</span>     <span class="o">|</span> <span class="n">READY</span>  <span class="o">|</span>
<span class="o">|</span> <span class="o">..</span>                   <span class="o">|</span> <span class="o">.</span>       <span class="o">|</span> <span class="o">..</span>     <span class="o">|</span>
<span class="o">|</span> <span class="o">..</span>                   <span class="o">|</span> <span class="o">.</span>       <span class="o">|</span> <span class="o">..</span>     <span class="o">|</span>
<span class="o">+----------------------+---------+--------+</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="o">...</span>
<span class="n">I1002</span> <span class="mi">21</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mf">57.891440</span> <span class="mi">62</span> <span class="n">grpc_server</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">3914</span><span class="p">]</span> <span class="n">Started</span> <span class="n">GRPCInferenceService</span> <span class="n">at</span> <span class="mf">0.0.0.0</span><span class="p">:</span><span class="mi">8001</span>
<span class="n">I1002</span> <span class="mi">21</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mf">57.893177</span> <span class="mi">62</span> <span class="n">http_server</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">2717</span><span class="p">]</span> <span class="n">Started</span> <span class="n">HTTPService</span> <span class="n">at</span> <span class="mf">0.0.0.0</span><span class="p">:</span><span class="mi">8000</span>
<span class="n">I1002</span> <span class="mi">21</span><span class="p">:</span><span class="mi">58</span><span class="p">:</span><span class="mf">57.935518</span> <span class="mi">62</span> <span class="n">http_server</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">2736</span><span class="p">]</span> <span class="n">Started</span> <span class="n">Metrics</span> <span class="n">Service</span> <span class="n">at</span> <span class="mf">0.0.0.0</span><span class="p">:</span><span class="mi">8002</span>
</pre></div>
</div>
<p>All the models should show “READY” status to indicate that they loaded correctly. If a model fails to load the status will report the failure and a reason for the failure. If your model is not displayed in the table check the path to the model repository and your CUDA drivers.</p>
</div>
<div class="section" id="run-on-cpu-only-system">
<h3>Run on CPU-Only System<a class="headerlink" href="#run-on-cpu-only-system" title="Permalink to this headline">#</a></h3>
<p>On a system without GPUs, Triton should be run without using the
–gpus flag to Docker, but is otherwise identical to what is described
above.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker run --rm -p8000:8000 -p8001:8001 -p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3 tritonserver --model-repository=/models
</pre></div>
</div>
<p>Because the –gpus flag is not used, a GPU is not available and Triton
will therefore be unable to load any model configuration that requires
a GPU.</p>
</div>
<div class="section" id="verify-triton-is-running-correctly">
<h3>Verify Triton Is Running Correctly<a class="headerlink" href="#verify-triton-is-running-correctly" title="Permalink to this headline">#</a></h3>
<p>Use Triton’s <em>ready</em> endpoint to verify that the server and the models
are ready for inference. From the host system use curl to access the
HTTP endpoint that indicates server status.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ curl -v localhost:8000/v2/health/ready
...
&lt; HTTP/1.1 200 OK
&lt; Content-Length: 0
&lt; Content-Type: text/plain
</pre></div>
</div>
<p>The HTTP request returns status 200 if Triton is ready and non-200 if
it is not ready.</p>
</div>
</div>
<div class="section" id="send-an-infernce-request">
<h2>Send an Infernce Request<a class="headerlink" href="#send-an-infernce-request" title="Permalink to this headline">#</a></h2>
<p>Use docker pull to get the client libraries and examples image
from NGC.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker pull nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3-sdk
</pre></div>
</div>
<p>Where &lt;xx.yy&gt; is the version that you want to pull. Run the client
image.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker run -it --rm --net=host nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3-sdk
</pre></div>
</div>
<p>From within the nvcr.io/nvidia/tritonserver:&lt;xx.yy&gt;-py3-sdk
image, run the example image-client application to perform image
classification using the example densenet_onnx model.</p>
<p>To send a request for the densenet_onnx model use an image from the
/workspace/images directory. In this case we ask for the top 3
classifications.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ /workspace/install/bin/image_client -m densenet_onnx -c 3 -s INCEPTION /workspace/images/mug.jpg
Request 0, batch size 1
Image &#39;/workspace/images/mug.jpg&#39;:
    15.346230 (504) = COFFEE MUG
    13.224326 (968) = CUP
    10.422965 (505) = COFFEEPOT
</pre></div>
</div>
</div>
</div>

<div class="section">
   
</div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../contents.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">&lt;no title&gt;</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../user_guide/performance_tuning.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Deploying your trained model using Triton</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By NVIDIA<br/>
  
      &copy; Copyright 2022 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.<br/>
    Last updated on Oct 05, 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


<script type="text/javascript">_satellite.pageBottom();</script>
  </body>
</html>